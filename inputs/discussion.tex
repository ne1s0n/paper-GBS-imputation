\section{Discussion}
\label{sec:discussion}

\subsection{Minor Allele Frequency and data (un)balancedness}
\label{sec:maf}
GBS data pose a greater challenge than SNP-array data to imputation algorithms, mainly as a consequence of the much larger quantity of missing genotypes they contain. On our data sets we found missing rates varied from 53\% to 67\%. With larger amounts of missing data the complexity of the imputation problem increases. Imputation error can have a negative impact on successive analyses (see for instance \cite{rutkoski_imputation_2013,Annicchiarico2015}).\\
The imputation of missing SNP genotypes is a special case of the broader family of classification problems: three-class missing genotypes (AA, AB and BB) at any given SNP locus are classified based on known genotypes at all remaining data points. Classification problems are known to be harder when data are unbalanced, i.e. the classes appear at different frequencies in the datasets, with typically one over-represented class
(see~\cite{kotsiantis_handling_2006}
and~\cite{sun_classification_2009} for a review). In SNP genotype imputation, data balancedness is directly related to the minor allele frequency (MAF). In the classification of unbalanced observations, it is important to look not only at the total classification accuracy, but also at the per-class accuracy. The total classification accuracy may be misleading, being ``dominated'' by the majority class
\cite{he_learning_2009}.
Indeed, we found that for most methods, even when the total classification accuracy was very high, relatively large error rates were present on minority classes. 
The dependency of imputation results on MAF has already been acknowledged  (e.g.,~\cite{hickey_factors_2012} in maize; \cite{ma_comparison_2013} in cattle; \cite{pei_analyses_2008} in humans). Our per-class dissection of results allowed a deeper insight into the imputation process. Indeed, all imputation algorithms performed considerably better in the majority class rather than in the less frequent classes.
In alfalfa, KNNI was easily the best imputation method in the heterozygous and minor homozygous classes, while SVDI and RFI performed only slightly better than MNI. In rice, Beagle gave the best imputation results, with accuracy close to 100\% both in the major and minor homozygous classes. MNI performed reasonably well in the alfalfa heterozygous class, with accuracy close 60\%, contributed to its moderately good results (total accuracy around 80\%).

\subsection{Missing rate and the ``curse of dimensionality''}
\label{sec:missing_rate_curse_dimensionality}
In general, imputation methods were relatively robust to increasing missing rates. Only KNNI, and to a lesser extent RFI, showed slowly degrading performances at very high missing rates. The divergent response of the different imputation methods to missing rate became apparent only in the most challenging scenarios, when markers with up to 40-70\% missing genotypes were allowed in the data set.\\
KNNI's decrease in imputation accuracy with increasing missing rates can be interpreted in relation to the phenomenon known as the ``curse of dimensionality'' \cite{bellman_dynamic_1957,marimont_nearest_1979}: with the same amount of data, the increasing number of parameters - the ``dimensions'' of the problem - increases and complicates the identification of k neighbors which are close enough to the data point to be classified/imputed. 
On average, the side $l$ of the hypercube to include $k$ neighbors is a function of $k$, $n$ (sample size) and $p$ (number of parameters): $l = \left ( \frac{k}{n} \right )^{1/p}$. With $n$ constant, the hypercube in which the $k$ neighbors lie gets bigger as $p$ increases. This holds especially for local learning methods (e.g.,~K-Nearest Neighbors methods, local regression) which rely heavily on the the information content of the neighbourhood. RFI - which only partially relies on local structure of the data - suffered marginally from high missingness. SVD and MNI, which build on more general properties of the data, and Beagle - whose learning process is fundamentally different and specific for genotype imputation - were scarcely affected by missing rates.

\subsection{Imputation efficiency: differences in rice vs. alfalfa}
\label{sec:role_of_species}
Imputation results were significantly different in rice and alfalfa: all imputation algorithms performed consistently better in rice data sets, where Beagle, RFI and KNNI achieved performances comparable to what is reported in literature for SNP-chip data (e.g.,~\cite{vanraden_genomic_2013} for bovine data;
\cite{the_1000_genomes_project_consortium_integrated_2012}
for human data). On the other hand, imputation accuracy in alfalfa data sets was much lower. This can be ascribed to four main factors: \\
i) the imputation problem was simpler in rice than in alfalfa, as the rice dataset comprised only pure lines, i.e. only two genotype classes instead of alfalfa's three; \\
ii) the genome structure was simpler in rice (diploid) than alfalfa (autotetraploid, rendered diploid ``in silico'' during SNP calling);\\
iii) alfalfa datasets did not contain population structure \cite{Annicchiarico2015}, while rice population was intrinsically stratified - being a collection of five subpopulation. Population structure is implicitly used by algorithms as Beagle and KNNI that create clusters of similar genotypes. Thus, rice dataset population structure facilitated the inputation process;\\
iv) rice data were analyzed by chromosome, allowing for higher average values of linkage disequilibrium (LD) among SNP markers, thus simplifying the imputation process.\\
Finally, the further difference in imputation accuracy between Alfalfa-Med and Alfalfa-PV suggests that other factors, directly connected to GBS protocols, may influence the general quality of the resulting data.\\
The most dramatic difference between data sets was found in FILLIN performances. The algorithm costantly produced 100\% uninputed results in alfalfa, while resulted in average performances in rice (albeit inferior to the other algorithms). This behaviour is probably due to FILLIN being designed to target inbred lines (as the name itself indicates).

\subsection{Reference genome assembly and ordered vs unordered markers}
\label{sec:reference_genome_ordered_vs_unordered}
When a reference genome is available, markers positions can be used in the imputation process. All methods specifically developed for the imputation of missing genotypes have been designed for markers ordered along the genome sequence, and make explicit or implicit use of position information.

For alfalfa there is no reference genome sequenced yet. The genome of the close relative diploid \emph{Medicago Truncatula} is available \cite{young_medicago_2011} and could in principle be used. However, while the two genomes show high synteny \cite{li_saturated_2014}, aligning the SNPs on a genome of a different species (and with a different ploidity) would introduce a further level of complexity, and the effect of alignments errors would be hardly assessable. Moreover, the non-aligning SNPs would be discarded, not on the basis of data quality, but of local synteny. We therefore decided to not use the genome of \emph{M. Truncatula} in the present analysis.

In rice, where a reference genome is available, we could assess the effect of using ordered vs. unordered markers for imputation. Among the imputation methods used in this study, Beagle is the only one to make use of marker information, and was therefore tested with ordered and randomly reshuffled markers. Interestingly, with ordered markers Beagle shows astounding resilience to high missingness, with imputation accuracy in the minority class $>$ 0.95 even in the most extreme scenarios (70\% allowed, 20\% artificial missing genotypes).

Beagle worked substantially worse when the marker position was randomly reshuffled, with imputation accuracy in the minority class ranging from 0.75 (10\% allowed, 1\% artificial missing rates) to almost 0.5 (70\% allowed, 20\% artificial missing rates). When tested with alfalfa (with no marker position available) Beagle largerly overestimated by the majority class, performing poorly
This result confirmed that imputation methods specifically designed for ordered markers are not an option for species lacking a reference genome.

Previous studies, though not detailing a per-class breakdown of the imputation accuracy, provided interesting comparisons. In sugar beet, Biscarini et al.~\cite{biscarini_genome-enabled_2014} used Beagle to impute SNP-chip markers with partial within-chromosome/scaffold alignment, finding global accuracies ranging from 84\% to 80.9\% with 1\% to 20\% missing genotypes. Huang et al.~\cite{huang_efficient_2014} tested several algorithms, including Beagle, on simulated ordered GBS rice data with missing rates in the 30-60\% range and finding Beagle gave imputation accuracy consistently higher (+15-20\%) than KNNI. 
Finally, Swarts et al.~\cite{swarts_novel_2014} used ordered GBS maize data to compare Beagle with the FSFHap and FILLIN algorithms they developed. All these algorithms rely on a Hidden Markov Model (HMM) to detect recombination break-points between haplotypes. They mostly obtained high imputation accuracies in the three genotype classes, providing further evidence of the added value of having a reference genome assembly.

\subsection{Size of the imputation problem}
\label{sec:size_of_problem}
Albeit this was not the main objective of the paper, and no formal effort to optimise the implementation of the various imputation methods was done, still the recorded computation times give us some interesting information.
The size of the problem, besides affecting the accuracy achievable by some imputation methods, is mainly relevant with reference to the required computation resources. RFI was the most demanding algorithm, with computation times growing exponentially both with the total number of marker genotypes (m SNP $\times$ n samples) and with the number of missing genotypes to be imputed. When analyzing the complete rice dataset (all chromosomes together), RFI took a maximum of about 40 days to complete imputation, and became computationally intractable (on the available platform) for the largest missing rate scenarios. This was partially mitigated by parallelization (we used 10 CPUs in our experiments). All other imputation algorithms took much shorter times to complete imputation, even in the most challenging scenarios. Putting together imputation accuracy and computation time, we found that the best performing imputation algorithms were Beagle in rice and KNNI in alfalfa.
