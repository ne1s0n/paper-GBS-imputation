\section{Discussion}
\label{sec:discussion}

\subsection{Minor Allele Frequency and data (un)balancedness}
\label{sec:maf}
GBS data pose a greater challenge than SNP-chip data to imputation algorithms, mainly as a consequence of the much larger quantity of missing genotypes they usually contain. On our data sets we found missing rates varying from 53\% to 67\%. With larger amounts of missing data the complexity of the imputation problem tends to increase. Moreover, with such a high level of missingness, even imputation errors as low as 1\% may have negative impact on successive analysis, amplifying the importance of finding the most accurate imputation method.\\
The imputation of missing SNP genotypes is a special case of the broader family of classification problems: three-class missing genotypes (AA, AB and BB) at any given SNP locus are classified based on known genotypes at all remaining data points. Classification problems are known to be harder when data are unbalanced, i.e. the classes appear at different frequencies in the datasets, with typically one over-represented class
%problem with url
(see~\cite{kotsiantis_handling_2006}
and~\cite{sun_classification_2009} for a review). In SNP genotype imputation, data balancedness is directly related to the minor allele frequency (MAF). In the classification of unbalanced observations, it is important to look not only at the total classification accuracy, but also at the per-class accuracy. The total classification accuracy may be misleading, being ``dominated'' by the majority class
%problem with url
\cite{he_learning_2009}.
The total classification accuracy can in fact be very high (close to 1) even with large error rates in the minority class. 
The dependency of imputation results on MAF has already been acknowledged  (e.g.,~\cite{hickey_factors_2012} in maize; \cite{ma_comparison_2013} in cattle; \cite{pei_analyses_2008} in humans). Our per-class dissection of results allowed a deeper insight into the imputation process. Indeed, all imputation algorithms performed considerably better in the majority class rather than in the less frequent classes.
Some algorithms failed almost completely the imputation of the least common genotypes, while other algorithms proved to work well. In alfalfa, KNNI was easily the best imputation method in the heterozygous and minor homozygous classes, while SVDI and RFI performed only slightly better than MNI. In rice, Beagle gave the best imputation results, with accuracy close to 100\% both in the major and minor homozygous classes. MNI performed reasonably well in the alfalfa heterozygous class, with accuracy close to 0.6, contributed to its moderately good results (total accuracy around 0.8).

\subsection{Missing rate and the ``curse of dimensionality''}
\label{sec:missing_rate_curse_dimensionality}
In general, imputation methods were relatively robust to increasing missing rates. Only KNNI, and to a lesser extent RFI, showed slowly degrading performances at very high missing rates. The divergent response of the different imputation methods to missing rate became apparent only in the most challenging scenarios, when markers with up to 40-70\% missing genotypes were allowed in the data set.\\
KNNI's relatively pronounced drop in imputation accuracy with increasing missing rates can be interpreted in relation to the phenomenon known as the ``curse of dimensionality'' \cite{bellman_dynamic_1957,marimont_nearest_1979}: with the same amount of data, the increasing number of parameters - the ``dimensions'' of the problem - increases and complicates the identification of k neighbors which are close enough to the data point to be classified/imputed. 
On average, the side $l$ of the hypercube to include $k$ neighbors is a function of $k$, $n$ (sample size) and $p$ (number of parameters): $l = \left ( \frac{k}{n} \right )^{1/p}$. With $n$ constant, the hypercube in which the $k$ neighbors lie gets bigger as $p$ increases. This holds especially for local learning methods (e.g.,~K-Nearest Neighbors methods, local regression) which rely heavily on the the information content of the neighbourhood. RFI - which only partially relies on local structure of the data - suffered marginally from high missingness. SVD and MNI, which build on more general properties of the data, and Beagle - whose learning process is fundamentally different and specific for genotype imputation - were scarcely affected by missing rates.

\subsection{The role of the crop species: rice vs. alfalfa}
\label{sec:role_of_species}
Imputation results were significantly different in rice and alfalfa: all imputation algorithms performed consistently better in rice data sets, where Beagle, RFI and KNNI achieved performances comparable to what is reported in literature for SNP-chip data (e.g.,~\cite{vanraden_genomic_2013} for bovine data;
%problems with this citation: url contains hashes
\cite{the_1000_genomes_project_consortium_integrated_2012}
for human data). On the other hand, imputation accuracy in alfalfa data sets was much lower. This can be ascribed to three main factors: 
i) the imputation problem was simpler in rice than in alfalfa, as the rice dataset comprised only pure lines, i.e. only two genotype classes instead of alfalfa's three; 
ii) the genome structure was simpler in rice (diploid) than alfalfa (autotetraploid, rendered diploid ``in silico'' during SNP calling);
iii) rice data were analyzed by chromosome, allowing for higher average values of linkage disequilibrium (LD) among SNP markers, thus simplifying the imputation process.\\
Finally, the further difference in imputation accuracy between Alfalfa-Med and Alfalfa-PV suggests that other factors, directly connected to GBS protocols, may influence the general quality of the resulting data.

\subsection{Reference genome assembly and ordered vs unordered markers}
\label{sec:reference_genome_ordered_vs_unordered}
When a reference genome is available, markers positions can be used in the imputation process. All methods specifically developed for the imputation of missing genotypes have been designed for markers ordered along the genome sequence, and make explicit or implicit use of position information.
For alfalfathere is no reference genome sequenced yet. The genome of the close relative diploid \emph{Medicago Truncatula} is available \cite{young_medicago_2011} and could in principle be used. However, while the two genomes show high synteny \cite{li_saturated_2014}, aligning the SNPs on a genome of a different species (and with a different ploidity) would introduce a further level of complexity, and the effect of alignments errors would be hardly assessable. Moreover, the non-aligning SNPs would be discarded, not on the basis of data quality, but of local synteny. We therefore decided to not use the genome of \emph{M. Truncatula} in the present analysis.\\
In rice, where a reference genome is available, we could assess the effect of using ordered vs. unordered markers for imputation. Among the imputation methods used in this study, Beagle is the only one to make use of marker information, and was therefore tested with ordered and randomly reshuffled markers. Interestingly, with ordered markers Beagle shows astounding resilience to high missingness, with imputation accuracy in the minority class $>$ 0.95 even in the most extreme scenarios (70\% allowed, 20\% artificial missing genotypes).
Beagle worked substantially worse when the marker position was randomly reshuffled, with imputation accuracy in the minority class ranging from 0.75 (10\% allowed, 1\% artificial missing rates) to almost 0.5 (70\% allowed, 20\% artificial missing rates). When tested with alfalfa (with no marker position available) Beagle largerly overestimated by the majority class, performing poorly
This result confirmed that imputation methods specifically designed for ordered markers are not an option for species lacking a reference genome.\\
Previous studies, though not detailing a per-class breakdown of the imputation accuracy, provided interesting comparisons. In sugar beet, Biscarini et al.~\cite{biscarini_genome-enabled_2014} used Beagle to impute SNP-chip markers with partial within-chromosome/scaffold alignment, finding global accuracies ranging from 84\%to 80.9\% with 1\% to 20\% missing genotypes. Huang et al.~\cite{huang_efficient_2014} tested several algorithms, including Beagle, on simulated ordered GBS rice data with missing rates in the 30-60\% range and finding Beagle gave imputation accuracy consistently higher (+15-20\%) than KNNI. 
Finally, Swarts et al.~\cite{swarts_novel_2014} used ordered GBS maize data to compare Beagle with the FSFHap and FILLIN algorithms they developed. All these algorithms rely on a Hidden Markov Model (HMM) to detect recombination break-points between haplotypes. They mostly obtained high imputation accuracies in the three genotype classes, providing further evidence of the added value of having a reference genome assembly.

\subsection{Size of the problem}
\label{sec:size_of_problem}
The size of the problem, besides affecting the accuracy achievable by some imputation methods, is mainly relevant with reference to the required computation resources. RFI was the most demanding algorithm, with computation times growing exponentially both with the total number of marker genotypes (m SNP $\times$ n samples) and with the number of missing genotypes to be imputed. When analyzing the complete rice dataset (all chromosomes together), RFI took a maximum of about 40 days to complete imputation, and became computationally intractable (on the available platform) for the largest missing rate scenarios. This was partially mitigated by parallelization (we used 10 CPUs in our experiments). All other imputation algorithms took much shorter times to complete imputation, even in the most challenging scenarios. Putting together imputation accuracy and computation time, we found that the best performing imputation algorithms were Beagle in rice and KNNI in alfalfa.\\
The analysis of the rice complete data set (437 samples $\times$ 166\,418 SNP markers) offered interesting insights on the applicability of imputation methods. While problems related to the computational requirements can usually be tackled by the constant improvement in bioinformatics facilities, current trends in genotyping suggest that imputation methods and computational strategies well suited for large data sets are to be preferred. The non-linearity of computational efficiency generated, for most examined imputation algorithms, a total computation time for the complete rice data set which was greater than the sum of the computation times required by the individual chromosomes. Again, RFI provided the most blatant illustration of this behavior, with computation times for the complete rice data set going up to 937 hours (about 40 days), while the sum of the computation times for all the single chromosomes in the same experimental conditions added to 88.3 hours.
