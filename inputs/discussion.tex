\section{Discussion}
\label{sec:discussion}

\subsection{Minor Allele Frequency and data (un)balancedness}
\label{sec:maf}
GBS data pose a greater challenge than SNP-array data to imputation algorithms, mainly as a consequence of the much larger quantity of missing genotypes they contain. On our data sets we found missing rates varied from 53\% to 67\%. With larger amounts of missing data the complexity of the imputation problem increases. Imputation errors can have a negative impact on successive analyses (e.g. on genomic predictions \cite{rutkoski_imputation_2013,Annicchiarico2015}).\\
The imputation of missing SNP genotypes is a special case of the broader family of classification problems: three-class missing genotypes (AA, AB and BB) at any given SNP locus are classified based on known genotypes at all remaining data points. Classification problems are known to be harder when data are unbalanced, i.e. the classes appear at different frequencies in the datasets, with typically one over-represented class
(see~\cite{kotsiantis_handling_2006}
and~\cite{sun_classification_2009} for a review). In SNP genotype imputation, data balancedness is directly related to the minor allele frequency (MAF). In the classification of unbalanced observations, it is important to look not only at the total classification accuracy, but also at the per-class accuracy. The total classification accuracy may be misleading, being ``dominated'' by the majority class
\cite{he_learning_2009}.
Indeed, we found that for most methods, even when the total classification accuracy was very high, relatively large error rates were present on minority classes. 
The dependency of imputation results on MAF has already been acknowledged  (e.g.,~\cite{hickey_factors_2012} in maize; \cite{ma_comparison_2013} in cattle; \cite{pei_analyses_2008} in humans). Our per-class dissection of results allowed a deeper insight into the imputation process. Indeed, all imputation algorithms performed considerably better in the majority class rather than in the less frequent classes.
In alfalfa, KNNI was easily the best imputation method in the heterozygous and minor homozygous classes, while SVDI and RFI performed only slightly better than MNI. In rice, Beagle gave the best imputation results, with accuracy close to 100\% both in the major and minor homozygous classes.

\subsection{Missing rate and the ``curse of dimensionality''}
\label{sec:missing_rate_curse_dimensionality}
In general, imputation methods were relatively robust to increasing missing rates. Only KNNI, and to a lesser extent RFI, showed slowly degrading performances at very high missing rates. The divergent response of the different imputation methods to missing rate became apparent only in the most challenging scenarios, when markers with up to 40-70\% missing genotypes were allowed in the data set.\\
KNNI's decrease in imputation accuracy with increasing missing rates can be interpreted in relation to the phenomenon known as the ``curse of dimensionality'' \cite{bellman_dynamic_1957,marimont_nearest_1979}: with the same amount of data, the increasing number of parameters - the ``dimensions'' of the problem - increases and complicates the identification of k neighbors which are close enough to the data point to be classified/imputed. 
On average, the side $l$ of the hypercube to include $k$ neighbors is a function of $k$, $n$ (sample size) and $p$ (number of parameters): $l = \left ( \frac{k}{n} \right )^{1/p}$. With $n$ constant, the hypercube in which the $k$ neighbors lie gets bigger as $p$ increases. This holds especially for local learning methods (e.g.,~K-Nearest Neighbors methods, local regression) which rely heavily on the the information content of the neighborhood. RFI - which only partially relies on local structure of the data - suffered marginally from high missingness. SVD and MNI, which build on more general properties of the data, and Beagle - whose learning process is fundamentally different and specific for genotype imputation - were scarcely affected by missing rates.

\subsection{Imputation efficiency: differences in rice vs. alfalfa}
\label{sec:role_of_species}
Imputation results were significantly different in rice and alfalfa: all imputation algorithms performed consistently better in rice, where Beagle, RFI and KNNI achieved performances comparable to what is reported in literature for SNP-chip data (e.g.,~\cite{vanraden_genomic_2013} for bovine data;
\cite{the_1000_genomes_project_consortium_integrated_2012}
for human data). On the other hand, imputation accuracy in alfalfa data sets was much lower. This can be ascribed to four main factors: \\
i) the imputation problem was simpler in rice than in alfalfa, since the rice dataset comprised only two genotype classes (AA and BB) instead of alfalfa's three (AA, AB, BB); \\
ii) rice is natively diploid while alfalfa, autotetraploid, has been rendered diploid ``in silico'' during SNP calling. This semplification step made alfalfa data less adherent to the underlying biology;\\
iii) rice data have higher marker density (2.4~Kbp/SNP, compared to 24.5~Kbp/SNP for Alfalfa-PV and 19.6~Kbp/SNP for Alfalfa-Med) due to both a higher number of markers and a smaller genome (400~Mb for rice, 800~Mb for Alfalfa). This allowed for higher average values of linkage disequilibrium (LD) among SNP markers, thus facilitating the imputation process;\\
iv) rice markers were aligned on their native genome, while alfalfa markers were aligned on a different species.

%
%The most dramatic difference between datasets was found with FILLIN. The algorithm costantly produced 100\% uninputed results in alfalfa, while resulted in average performances in rice (albeit inferior to the other algorithms). This behaviour is probably due to FILLIN being specifically designed to target inbred lines (as the name itself indicates).
%

There was no population structure in alfalfa \cite{Annicchiarico2015}, while the rice dataset was intrinsically stratified ---being a collection of five subpopulations (\textit{indica}, \textit{temperate japonica} \textit{tropical japonica}, \textit{aus} and \textit{aromatic}). Most imputation methods implicitly exploit population structure (e.g. KNNI computes distances based on genetic relatedness; Beagle reconstructs haplotypes based on genetic similarities), without explicitly modelling it. The imputation of missing genotypes, however, is not an inferential problem such as GWAS (genome-wide association study), where the significance and estimate of SNP effects are known to be inflated if population structure is not included in the model, and the impact on the accuracy of imputation is likely to be small. In cattle from Scandinavian countries, Brondum et al \cite{brondum2012short} actually found higher imputation accuracy when combining populations (cattle breeds) in Beagle (without explicitly modelling the population structure), most likely as a result of the larger sample size. On the other hand, population stratification may help explain why FILLIN performed poorly in our rice dataset, which is a collection of subpopulations, while this algorithm is optimised for homogeneous inbred populations. 
However, the influence of population structure on the accuracy of imputation was not formally tested in this work, and this remains an interesting topic for further investigation.


\subsection{Reference genome assembly and ordered vs unordered markers}
\label{sec:reference_genome_ordered_vs_unordered}
When a reference genome is available, marker position can be used in the imputation process. All methods specifically developed for the imputation of missing genotypes have been designed for markers ordered along the genome sequence, and make explicit or implicit use of position information.

In rice, where a reference genome is available, we could assess the effect of using ordered vs. unordered markers for imputation. For alfalfa there is no reference genome sequenced yet. The genome of the close relative diploid \emph{Medicago Truncatula} is available \cite{young_medicago_2011} and can in principle be used. However, while the two genomes show high synteny \cite{li_saturated_2014}, aligning on a different species (and with different ploidity) comes at the price of discarding those markers that do not align. In our case only 57.54\% (Alfalfa-Med) and 57.86\% (Alfalfa-PV) aligned on the \emph{M. Truncatula} genome, compared to the 88.66\% of rice markers aligning on \emph{O. Sativa} genome. This left with 23\,438 and 18\,923 SNPs to be used for analysis with ordered markers. \\
Among the imputation methods used in this study, Beagle and FILLIN are the only ones that make use of marker information, and were therefore tested with ordered and randomly shuffled markers. In rice dataset with ordered markers Beagle showed astounding resilience to high missingness, with imputation accuracy in the minority class $>$95\% even in the most extreme scenarios (70\% allowed, 20\% artificial missing genotypes).
Beagle worked substantially worse when the marker position was randomly reshuffled, with imputation accuracy in the minority class ranging from 75\% (10\% allowed, 1\% artificial missing rates) to almost 50\% (70\% allowed, 20\% artificial missing rates). When tested with alfalfa Beagle largerly overestimated the majority class and had very poor performances on the heterozygous class. Shuffling marker positions further worsened Beagle performance in alfalfa, and almost all missing genotypes were assigned to the majority class.\\
FILLIN performance in rice followed the same pattern and was substantially worse when markers were shuffled. This result confirmed that imputation methods specifically designed for ordered markers are not an option for species lacking a reference genome.

Previous studies, though not detailing a per-class breakdown of the imputation accuracy, provide interesting comparisons. In sugar beet, Biscarini et al.~\cite{biscarini_genome-enabled_2014} used Beagle to impute SNP-chip markers with partial within-chromosome/scaffold alignment, finding global accuracies ranging from 84\% to 80.9\% with 1\% to 20\% missing genotypes. Huang et al.~\cite{huang_efficient_2014} tested several algorithms, including Beagle, on simulated ordered GBS rice data with missing rates in the 30-60\% range and finding Beagle gave imputation accuracy consistently higher (+15-20\%) than KNNI. 
Finally, Swarts et al.~\cite{swarts_novel_2014} used ordered GBS maize data to compare Beagle with the FSFHap and FILLIN algorithms they developed. They mostly obtained high imputation accuracies in the three genotype classes, providing further evidence of the added value of having a reference genome assembly.

\subsection{Size of the imputation problem}
\label{sec:size_of_problem}
Albeit this was not the main objective of the paper, and no formal effort to optimise the implementation of the various imputation methods was done, still the recorded computation times give us some interesting information.
The size of the problem, besides affecting the accuracy achievable by some imputation methods, is mainly relevant with reference to the required computation resources. RFI was the most demanding algorithm, with computation times growing exponentially both with the total number of marker genotypes (m SNP $\times$ n samples) and with the number of missing genotypes to be imputed. When analyzing the complete rice dataset (all chromosomes together), RFI took a maximum of about 40 days to complete imputation, and became computationally intractable (on the available platform) for the largest missing rate scenarios. This was partially mitigated by parallelization (we used 10 CPUs in our experiments). All other imputation algorithms took much shorter times to complete imputation, even in the most challenging scenarios. Putting together imputation accuracy and computation time, we found that the best performing imputation algorithms were Beagle in rice and KNNI in alfalfa.
